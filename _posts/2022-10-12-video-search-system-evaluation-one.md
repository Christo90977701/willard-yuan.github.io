---
layout: post
title: 搜索系统：视频搜索离线指标与在线指标
categories: [Cpp]
tags: Cpp
---

## 背景

搜索是一个以相关性为基础，辅助消费、权威、质量、时鲜等多目标的复杂系统。

各位看官在搜索引擎输入一个Query位“如何在mate 40上连接wifi”，我们优先考虑的是排序的doc是否与Query相关，根据相关的程度，可以有不一样的定义：

| doc内容 | 相关性得分 | 解释 |
| :-----:| :----: | :----: |
| doc内容就是在介绍华为mate 40怎么连接wifi | 3 | 用户输入Query完全匹配doc，给最高分 |
| doc内容在介绍华为mate 30怎么连接wifi | 2 | 用户输入Query意图匹配，且mate 40和mate 30基本上都是一个系列，看了mate30的连接wifi方法，也能解决mate 40连接wifi的方法 |
| doc内容在介绍华为 mate 40，但是没有介绍怎么连接wifi | 1 | 核心实体完全匹配，但是用户的主需求没有得到满足 |
| doc内容基本上都在介绍联想电脑怎么连接wifi | 0 | 用户输入Query与doc主题完全不匹配 |

从上述定义看出，不考虑权威、质量等，相关性的评估就是一件很难的事情。首先标准的确定就需要很强的业务视角做背书，3分和0分的区别很容易，但是如何拉开2分和1分区分度，也是一个世纪难题；作为一个算法工程师，我们要为业务效果负责，常见的工作目标设定就是定一个合理的过程指标，来帮助我们进行目标的迭代。

很多做推荐的同学有可能会说，我们离线搞一个点击的AUC，AUC提升证明模型效果不错，然后我们在线去看点击率不就能衡量了么？那我举一个真实的用户Query“杨颖”，如果出只包含“黄晓明”的结果，用户的点击不但不掉，还会升，这个时候我们发现指标失效了，因为用户输入Query的意图很明确就是找“杨颖”这个人，而不是找他老公“黄晓明”，且在相关性的评估角度，这个就是典型的0分问题。

搜索和推荐最大的不同是：

- 推荐可以依托自动化的指标来辅助我们迭代，毕竟推得好不好，可以通过用户的点击行为来进行衡量，推荐的相关一般定义为沾边就可以了，搜索的相关可是有明确的定义的，用户本身用推荐就是一个被动行为，容错率会更高一些，而搜索是一个主动行为，容错率会更低。

- 在用户和doc之间加入了一个枷锁，这个枷锁就是Query，只有Query和doc满足相关性的要求，我们才能在相关性的基础上刻画时效、权威、质量、满意度等其他多维度的指标。那么我们进行搜索项目的迭代，到底要依托什么样子的过程指标呢？什么才是搜索系统的北极星指标呢？

## 在线与离线指标

### 在线指标

做过综合搜索的人应该都知道，业界主流的搜索AB指标会有很多，北极星指标是DAU，重要指标包括有点比、首点位置和换Query率，以及其他一些消费指标。

- DAU：当用户搜索心智建立之后，需要去刺激用户去不断使用，进而提升整体DAU，这个是北极星指标，其他指标都是参考，正常搜索做的好，DAU是不断提升的。
- PV：搜索核心业务指标，重要性仅次于DAU，搜索商业化和这个指标非常相关，但是PV涨不见得是一个好事，当我们搜索服务不稳定的时候，用户频繁发生换query检索，换query率负向，但是PV是涨的。
- 首页有点比：有点击的query/所有query，这个指标一定程度能反应出线上相关性，但这个指标有天花板，想突破80%都很难。
- 换query率：用户一般在一个session中，如果已经搜到满意的结果，是不会换一个query来进一步检索的，换query率变低，相关性满足的还不错；但是也不能完全迷信这个指标，有可能用户觉得搜索结果很差，就不愿意相信搜索结果了。
- 首次点击位置：那些最相关的结果更应该排在靠前的位置，这个很符合NDCG的定义，3分的最相关的结果更应该排在第一位，首次点击位置一定程度能反应相关性。
- 浏览深度：搜索是满足既走，如果第一条已经满足我们的要求了，那么就没有必要再去浏览下一条，这个指标更多的是一个横向参考指标，需要和其他指标集合看，如果我们的换query正向，消费指标也正向，浏览深度反而能帮助我们提升用户感知，更好的消费；但是如果换query变多，消费指标一般，而浏览深度增加，证明我们整体满足用户搜索需求做的不好。
- 消费指标：点击率、停留时长、完播率、点赞率等常见的消费指标，这些指标是短期的业务指标，主要是通过多目标帮助提升用户体验，进而长期提升DAU，因为相关性好，不一定消费指标好，我们更应该把相关性和满意度好的都呈现给我们的用户。

我们做一个假设，用户输入了一个Query，如果相关，那么用户肯定会点下方的Doc，有点比会变高；理论上越相关的Doc应该排在更靠前的位置，用户不需要向下浏览就可以找到目标的Doc，首次点击的位置会靠前；如果满足了用户的搜索需求，用户大概率不会对之前的Query做修正来重新找到目标的Doc。

但是上述的AB指标只是用户用脚投票的结果，而相关性是一个相对先验的东西，除非有很大的效果升级，且影响面够高，我们才能撼动AB指标。经过很多的经验论证，相关性提升是一个顿感很强的模块，用户心智的养成需要时间培养，那么我们的单次实验迭代如果没有撼动指标，我们还去参加LR么？

### 离线指标

其实业界各家主流的做法，会依赖于一个偏主观的NDCG或者side by side的人工GSB的评估：

#### 排序评估（NDCG）刻画相关性

- NDCG（DCG/IDCG）是学术界给搜索定的指标，会构造一套理想态的搜索结果（IDCG），然后观察当前搜索结果达到理想态的分数（是一个小于1的数，如果是0.9，代表达到理想态的90分）；但是搜索本身是一个长尾需求，数据分布随着需求变更，随着时间变化，数据集会差别很大。
我们以视频搜索为例，大家都会以抖音作为IDCG，然后去评比达到抖音的多少分，但是抖音是否是最优的，不确定。

- 还有一个指标就是DCG，就是自己和自己比，通过分数来看，目前能到8分基本上就是非常好的搜索引擎。

通过上述分析，NDCG是一个还不错的指标，但是不能作为整个搜索迭代唯一看的离线指标，因为数据集无法真正反应线上真实情况，只是作为一个Ground Truth参考。

#### 人工评估（GSB）刻画相关性

GSB的名称叫做Good: Same: Bad，各家搜索引擎真正相关性的评估标准，是遵循一个套严格的评判标准。。每次实验的迭代我们会将实验组和对照组进行随机词包（就是线上用户实际输入的Query包）抽取Diff，然后送给行业专家进行人工GSB评估，如果实验组好就会把当前的Query评估为Good，如果效果持平那么就是Same，否则就是Bad。

实际迭代过程中，会采用一套严格的人工标注流程，遵循side by side的评估手法，通过对相关性、权威性、质量、时效、多样等维度进行人工评估来去打出区分度，真正的做到离线迭代抽diff，gsb真正反应线上效果

上述做法依赖于行业专家定义的一套标准，分门别类的进行评估的一套规则系统，偏先验的东西需要有标准进行牵引。如果觉得评估过于主观，那么其实可以采用奇数人（如果是偶数的话，正好变成1:1，需要一个裁判介入做决定）评估的方式，并且将词包数量变大来减少Bias。

当然这种方式势必会被做行为建模的同学所诟病，但是还是那个问题，点击不点击只是相关不相关的一个子集而已，毕竟不相关也可以获得高点击，所以我们需要结合AB指标和人工评估统一来看，人工评估更多的是一种体感映射，依赖于行业专家，有时候会不客观，但实在是找不到更好的过程指标了。就相当于高考，很多人诟病它一考定终生，但是还有比它更好的评估方式么，毕竟存在也上千年了。

当然，现在一些先进的搜索系统，会提供一些人工反馈的入口，让用户去点击是否相关的按钮来进行反馈，也能获得一些有用的输入。这些也可以做成过程指标，这块不知道做过智能客服的同学是否有一定的体感？人工反馈本身就噪音很大，且反馈是一个小概率事件，统计的维度也不客观。我们也深入去分析过这样的数据，一半以上的反馈都是无用的，但是它也可以作为一个参考来辅助我们进行决策。

## 一些反直觉的误区探讨

### 用户点击是否代表相关

首先搜索的点击和推荐广告场景不一样，是先验和后验的融合，另外标题党严重，纯用点击来刻画相关性很不现实，直接会学飞，一般都是拿点击做pre train。搜索是一个主动的行为习惯，不是一个被动的行为习惯：包括质量、权威、时效、新鲜度等。而这些都是很难通过在线指标来刻画的，毕竟我们也发现，中国用户长搜的那些点击高的都是色情query，很容易带歪模型。另外短视频模式下，单列自动播放，怎么衡量用户点击？

### AB指标是否是搜索最优的流量实验？

AB指标更多是做分桶实验，而且是占用少量流量来做实验，很多公司都会采用类似于反转的操作保证指标不受短期影响，因为短期指标有可能是收到波动的影响，长期拉平没有任何收益，有可能是负向；常见一类情况，如果分桶后，桶内用户都是活跃的搜索用户，就会产生bias。

所以搜索更多的是采用interleaving实验，通过将不同策略的结果交织在一起来判断，这样可以有效的避开活跃用户这个坑。但是interleaving是否是最优方案，也不一定，只是说相对AB实验来说，更适合搜索场景。

搜索是一个复杂的系统，评估更是一个很难被科学量化的工作，往往也被人challenge，但是确实也没有更好的方式方法。